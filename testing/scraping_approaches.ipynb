{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bab283f",
   "metadata": {},
   "source": [
    "## Scraping with iframe\n",
    "\n",
    "This section scrapes the first page of the AI4Belgium website based on the content inside the `<iframe>` tag.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300cf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "def create_driver(url, headless= True):\n",
    "    # Setup Selenium WebDriver\n",
    "    print(\"Setting up WebDriver...\")\n",
    "    # Use ChromeDriverManager to automatically handle the ChromeDriver path\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    if headless:\n",
    "        chrome_options.add_argument(\"--headless=new\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    # Navigate to the page. We include the full URL.\n",
    "    driver.get(url)\n",
    "    print(f\"Navigating to {url}\")\n",
    "    return driver\n",
    "\n",
    "def click_cookie(driver,cookie_xpath):\n",
    "    try:\n",
    "        # Wait for GDPR Banner to load and reject optional cookies\n",
    "        time.sleep(5) \n",
    "        driver.find_element(By.XPATH, cookie_xpath).click()\n",
    "        print(\"Optional cookies rejected\")\n",
    "    except:\n",
    "        print(\"No GDPR cookie banner found! Continue ...\")\n",
    "\n",
    "def extract_company_data(root_url, company_item_css, iframe_css = None):\n",
    "\n",
    "    driver = create_driver(root_url)\n",
    "    cookie_xpath ='//*[@id=\"fedconsent\"]/div[1]/div/div/div/div/ul/li[3]/button'\n",
    "    click_cookie(driver, cookie_xpath)\n",
    "    # --- 1. Define Selectors ---\n",
    "    wait = WebDriverWait(driver, 10) # Use a generous wait time\n",
    "    dataset =[]\n",
    "    try:\n",
    "        # 2. WAIT for the IFRAME to be available and SWITCH to it\n",
    "        # EC.frame_to_be_available_and_switch_to_it is the most reliable method\n",
    "        print(\"Attempting to locate and switch to the iframe...\")\n",
    "        \n",
    "        if iframe_css != None:\n",
    "            wait.until(\n",
    "                EC.frame_to_be_available_and_switch_to_it((By.CSS_SELECTOR, iframe_css))\n",
    "            )\n",
    "            print(\"✅ Successfully switched to the iframe! WARNING: Script is build to only scrape first page!\")\n",
    "\n",
    "        # --- 3. Find the element INSIDE the iframe ---\n",
    "        company_items = driver.find_elements(By.CSS_SELECTOR, company_item_css.replace(\" > div:nth-child(1)\", \" > div \"))\n",
    "        print(f\"✅ Found the company item element(s)! Count: {len(company_items)}\")\n",
    "\n",
    "        # Example action: Get text from the first item\n",
    "    \n",
    "        for company in company_items:\n",
    "            company_data={}\n",
    "            try:\n",
    "                link_element = company.find_element(By.TAG_NAME, \"a\")\n",
    "                # Extract the URL (href)\n",
    "                url = link_element.get_attribute(\"href\")\n",
    "                text_header = company.find_element(By.TAG_NAME, \"h2\")\n",
    "                name = text_header.find_element(By.TAG_NAME,\"a\").text\n",
    "            except Exception as e:\n",
    "                url = None\n",
    "                name = None\n",
    "                print(f\"Warning: Could not fully extract data from url for{name}. Error: {e}\")\n",
    "                continue\n",
    "            try:       \n",
    "                # Find the image element inside the link\n",
    "                image_src = None\n",
    "                image_element = link_element.find_element(By.TAG_NAME, \"img\")\n",
    "                # Extract the image source (src)\n",
    "                image_src = image_element.get_attribute(\"src\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not fully extract data from image.\")\n",
    "                continue\n",
    "            try:\n",
    "                headers = company.find_elements(By.TAG_NAME, \"h4\")\n",
    "                header_info = company.find_elements(By.TAG_NAME, \"span\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not fully extract data from headers. Error: {e}\")\n",
    "                continue\n",
    "        \n",
    "            company_data[\"name\"] = name\n",
    "            company_data[\"url\"] = url\n",
    "            company_data[\"logo\"] = image_src\n",
    "            for header, info in zip(headers, header_info[1:]):\n",
    "                company_data[header.text.lower()] = info.text\n",
    "        \n",
    "            dataset.append(company_data)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Scraping failed after switching to iframe. Error: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        # Switch back to the main document context\n",
    "        if iframe_css != None:\n",
    "            driver.switch_to.default_content()\n",
    "            print(\"Switched back to default content.\")\n",
    "            driver.close()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "def save_list_dict_to_csv(dataset, output_file_path):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df.to_csv(output_file_path,index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb877062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up WebDriver...\n",
      "Navigating to https://bosa.belgium.be/nl/AI4Belgium/observatorium\n",
      "Optional cookies rejected\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Successfully switched to the iframe! WARNING: Script is build to only scrape first page!\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Switched back to default content.\n"
     ]
    }
   ],
   "source": [
    "iframe_css =\"#theme-content > div.field.field--name-field-blocks.field--type-entity-reference-revisions.field--label-hidden > ul > li:nth-child(4) > div > div > div > div > p:nth-child(4) > div > iframe\"\n",
    "company_item_css = \"div.grid.grid-cols-4.gap-3.mb-2 > div:nth-child(1)\"\n",
    "\n",
    "root_url = \"https://bosa.belgium.be/nl/AI4Belgium/observatorium\"\n",
    "dataset = extract_company_data(root_url, company_item_css, iframe_css)\n",
    "df = save_list_dict_to_csv(dataset, \"../data/first_page_iframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ffb3a7",
   "metadata": {},
   "source": [
    "## Scraping from underlying HTML pages\n",
    "In the previous section we noticed, we can directly scrape the information for startups by using the url: \n",
    "\n",
    "`https://community.ai4belgium.be/en/ai-landscape?nav=0&page={i}`\n",
    "\n",
    "and loop through the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3fdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=1\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=1\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=2\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=2\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=3\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=3\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=4\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=4\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=5\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=5\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=6\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=6\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=7\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=7\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=8\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=8\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=9\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=9\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=10\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=10\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=11\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=11\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=12\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=12\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=13\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=13\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=14\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=14\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=15\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=15\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=16\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=16\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=17\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=17\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 25\n",
      "Warning: Could not fully extract data from image.\n",
      "https://community.ai4belgium.be/en/ai-landscape?nav=0&page=18\n",
      "Setting up WebDriver...\n",
      "Navigating to https://community.ai4belgium.be/en/ai-landscape?nav=0&page=18\n",
      "No GDPR cookie banner found! Continue ...\n",
      "Attempting to locate and switch to the iframe...\n",
      "✅ Found the company item element(s)! Count: 0\n"
     ]
    }
   ],
   "source": [
    "def scrape_pages_ai4belgium(pages = 18):\n",
    "    company_item_css = \"div.grid.grid-cols-4.gap-3.mb-2 > div:nth-child(1)\"\n",
    "    combined_data = pd.DataFrame()\n",
    "    num_pages = pages\n",
    "    for page_num in range(1,num_pages+1):\n",
    "        suburl = f\"https://community.ai4belgium.be/en/ai-landscape?nav=0&page={page_num}\"\n",
    "        print(suburl)\n",
    "        dataset = extract_company_data(suburl, company_item_css)\n",
    "        df = pd.DataFrame(dataset)\n",
    "        combined_data = pd.concat([combined_data,df], ignore_index=True)\n",
    "\n",
    "    combined_data.to_csv(\"../data/raw_scraped_dataset.csv\", index = False)\n",
    "    return combined_data\n",
    "\n",
    "scrape_pages_ai4belgium()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a2cfc",
   "metadata": {},
   "source": [
    "## Scraping company address\n",
    "\n",
    "1. Using the https://kbopub.economie.fgov.be/ website that contains information about registered entities.\n",
    "2. Google search for those companies that don't have their legal entity registered\n",
    "\n",
    "If the company is not listed in the Belgian registry and their website is not active, we will exclude it from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c19879d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_from_dom_tree_CBE(url, xpath):\n",
    "    response = requests.get(url, headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"})\n",
    "    soup = BeautifulSoup(response.content,\"html.parser\")\n",
    "    # Convert to etree for XPath\n",
    "    dom = etree.HTML(str(soup))\n",
    "    try: \n",
    "        street= dom.xpath(xpath+'[1]')[0].replace(\"\\xa0\",\" \")\n",
    "        zip_code, city = dom.xpath(xpath+'[2]')[0].split(\"\\xa0\") \n",
    "    except:\n",
    "         street, zip_code, city =  None, None, None\n",
    "    return [street, zip_code, city]\n",
    "\n",
    "def extract_address_CBE(company_name):\n",
    "       # Extract street address using XPath\n",
    "        try:\n",
    "            # We use the exact name search \n",
    "            cbe_url = f\"https://kbopub.economie.fgov.be/kbopub/zoeknaamexactform.html?natuurlijkPersoon=vestiging&searchWord=&firmName=&_oudeBenaming=on&establishmentname={company_name}&rechtsvormFonetic=ALL&firstName=&postcode=&postgemeente1=&filterEnkelActieve=true&_filterEnkelActieve=on&actionNPRP=Search\"\n",
    "            exact_name_xpath = '//*[@id=\"vestiginglist\"]/tbody/tr/td[6]/text()'\n",
    "            return extract_from_dom_tree_CBE(cbe_url, exact_name_xpath)     \n",
    "        except:\n",
    "            # If that fails, we use the general name search\n",
    "            cbe_url = f\"https://kbopub.economie.fgov.be/kbopub/zoeknaamfonetischform.html?lang=en&searchWord={company_name}&_oudeBenaming=on&pstcdeNPRP=&postgemeente1=&ondNP=true&_ondNP=on&ondRP=true&_ondRP=on&rechtsvormFonetic=ALL&vest=true&_vest=on&filterEnkelActieve=true&_filterEnkelActieve=on&actionNPRP=Search\"\n",
    "            general_name_xpath = '//*[@id=\"onderneminglistfonetisch\"]/tbody/tr/td[6]/text()'\n",
    "            return extract_from_dom_tree_CBE(cbe_url, general_name_xpath)   \n",
    "\n",
    "extract_address_CBE(\"AdShot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74081fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude:50.66389, Longitude:4.6387666\n",
      "{'place_id': 95913698, 'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright', 'osm_type': 'way', 'osm_id': 661016916, 'lat': '50.6638900', 'lon': '4.6387666', 'class': 'highway', 'type': 'unclassified', 'place_rank': 26, 'importance': 0.05338644464789803, 'addresstype': 'road', 'name': 'Granbonpré', 'display_name': 'Granbonpré, Parc Fleming, Louvain-la-Neuve, Ottignies-Louvain-la-Neuve, Nivelles, Brabant wallon, Wallonie, 1348, België / Belgique / Belgien', 'boundingbox': ['50.6626136', '50.6654084', '4.6371223', '4.6406426']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# OpenStreetMap API\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# We use the address column to obtain the geocodes for each company\n",
    "geolocator = Nominatim(user_agent=\"http\", timeout= 10) \n",
    "geocoded_address = geolocator.geocode(\"Granbonpré,1348,Ottignies-Louvain-la-Neuve\")\n",
    "print(f\"Latitude:{geocoded_address.latitude}, Longitude:{geocoded_address.longitude}\")\n",
    "print(geocoded_address.raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
